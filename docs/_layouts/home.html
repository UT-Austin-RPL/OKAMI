<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OKAMI: Teaching Humanoid Robots Manipulation 
        Skills through Single Video Imitation">
  <meta name="keywords" content="OKAMI, Humanoid Manipulation, Imitation From Videos, Motion Retargeting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="icon" href="">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/chroma-js/2.1.1/chroma.min.js"></script>

  <script type="text/javascript" src="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.min.js"></script>

  <script defer src="./static/js/fontawesome.all.min.js"></script>

  <!-- Add the slick-theme.css if you want default styling -->
  <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.css"/>
  <!-- Add the slick-theme.css if you want default styling -->
  <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick-theme.css"/>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.3/gh-fork-ribbon.min.css" />

  <script src="./static/js/index.js"></script>

  <style>
    .has-text-red {
      color: #bf5700;
    }
    
    .s {
      color: #d14
    }
    
    .na {
      color: #008080
    }
    
    .nc {
      color: #445588;
      font-weight: bold
    }
    
    .nl {
      color: #990000;
      font-weight: bold
    }
    .bibref {
      font-family: Consolas, "Liberation Mono";
    }
  </style>

</head>
<body>
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation</h1>
          
          <!-- include the title info. It's located in _includes/title_info.html -->
          <div class="publication-authors">
    
      <span class="author-block">
        <a href=""> Jinhan Li<sup>1</sup>&nbsp&nbsp
        </a>
        </span>
          
      <span class="author-block">
        <a href="https://zhuyifengzju.github.io/"> Yifeng Zhu<sup>*1</sup>&nbsp&nbsp
        </a>
        </span>
    
      <span class="author-block">
        <a href="https://xieleo5.github.io/"> Yuqi Xie<sup>*1,2</sup>&nbsp&nbsp
        </a>
        </span>
    
      <span class="author-block">
        <a href="https://zhenyujiang.me/"> Zhenyu Jiang<sup>*1,2</sup>&nbsp&nbsp
        </a>
        </span>
    
      <span class="author-block">
        <a href="https://mingyoseo.com/"> Mingyo Seo<sup>1</sup>&nbsp&nbsp
        </a>
        </span>

      <span class="author-block">
        <a href="https://geopavlakos.github.io/"> Georgios Pavlakos<sup>1</sup>&nbsp&nbsp
        </a>
        </span>

      <span class="author-block">
        <a href="https://cs.utexas.edu/~yukez"> Yuke Zhu<sup>1,2</sup>&nbsp&nbsp
        </a>
        </span>
    
  </div>

  <div class="publication-authors">
    
      <span class="author-block">
        <sup>1 </sup> The University of Texas at Austin
      </span>
    
      <span class="author-block">
        <sup>2 </sup> Nvidia Research
      </span>
  </div>

  <p class="is-size-6"> <sup>*</sup>: Equal Contributions </p>
  
  <div class="publication-authors">
    <span class="author-block has-text-red">
      Conference on Robot Learning (CoRL), 2024
    </span>
  </div>
  
  <div class="column has-text-centered">
    <div class="publication-links">
      <span class="link-block">
        <!-- TODO: replace with pub link -->
        <a href="http://arxiv.org/abs/2410.11792"
           class="external-link button is-normal is-rounded">
          <span class="icon">
              <i class="ai ai-arxiv"></i>
          </span>
          <span>arXiv</span>
        </a>
      </span>
      <!-- <span class="link-block">
        <a href="https://youtu.be/hubAbximDuc"
           class="external-link button is-normal is-rounded">
          <span class="icon">
              <i class="fab fa-youtube"></i>
          </span>
          <span>Video</span>
        </a>
      </span>  -->
      <!-- PDF Link. -->
      <!-- <span class="link-block">
        <a href="https://zhuyifengzju.github.io/files/OKAMI_CoRL2023.pdf"
           class="external-link button is-normal is-rounded">
          <span class="icon">
              <i class="fas fa-file-pdf"></i>
          </span>
          <span>Paper</span>
        </a>
      </span>
      <span class="link-block">
        <a href="http://arxiv.org/abs/2310.14386"
           class="external-link button is-normal is-rounded">
          <span class="icon">
              <i class="ai ai-arxiv"></i>
          </span>
          <span>arXiv</span>
        </a>
      </span>
      <!- - Video Link. - ->
      <span class="link-block">
        <a href="https://youtu.be/T_wW-Mzt49M?si=QU7_e5xOpIfAH8RN"
           class="external-link button is-normal is-rounded">
          <span class="icon">
              <i class="fab fa-youtube"></i>
          </span>
          <span>Video</span>
        </a>
      </span> -->
      <!-- Code Link. -->
      <!-- <span class="link-block">
        <a href="#"
           class="external-link button is-normal is-rounded">
          <span class="icon">
              <i class="fab fa-github"></i>
          </span>
          <span>Coming Soon</span>
          </a>
      </span> -->
      <!-- <span class="link-block">
        <a href="https://zhuyifengzju.github.io/bibtex/okami.txt"
            class="external-link button is-normal is-rounded">
          <span class="icon">
            <svg class="svg-inline--fa fa-bibtex fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="bibtex" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 120 120" data-fa-i2svg=""><path fill="currentColor" d="m 29.09375,11.234375 c -3.183804,0 -5.71875,2.566196 -5.71875,5.75 l 0,94.031255 c 0,3.1838 2.534946,5.75 5.71875,5.75 l 69.8125,0 c 3.1838,0 5.71875,-2.5662 5.71875,-5.75 l 0,-70.656255 -21.03125,0 c -4.306108,0 -8.0625,-3.141109 -8.0625,-7.3125 l 0,-21.8125 -46.4375,0 z m 50.4375,0 0,21.8125 c 0,1.714122 1.631968,3.3125 4.0625,3.3125 l 21.03125,0 -25.09375,-25.125 z m -46.1875,51.3125 19.03125,0 0.25,5.46875 -0.625,0 c -0.126107,-0.962831 -0.313482,-1.64983 -0.53125,-2.0625 -0.355356,-0.664804 -0.841468,-1.159242 -1.4375,-1.46875 -0.584605,-0.320929 -1.349667,-0.499979 -2.3125,-0.5 l -3.28125,0 0,17.84375 c -1.2e-5,1.432815 0.15925,2.300914 0.46875,2.65625 0.435561,0.481426 1.094449,0.718751 2,0.71875 l 0.8125,0 0,0.625 -9.875,0 0,-0.625 0.8125,0 c 0.985768,10e-7 1.712342,-0.278949 2.125,-0.875 0.252166,-0.366798 0.343741,-1.193273 0.34375,-2.5 l 0,-17.84375 -2.8125,0 c -1.088943,2.1e-5 -1.854004,0.08955 -2.3125,0.25 -0.596054,0.217809 -1.107139,0.631046 -1.53125,1.25 -0.424114,0.618995 -0.66977,1.476719 -0.75,2.53125 l -0.65625,0 0.28125,-5.46875 z m 37.3125,0 10.78125,0 0,0.625 c -0.91701,0.03441 -1.562385,0.173884 -1.90625,0.4375 -0.332422,0.263659 -0.500009,0.554071 -0.5,0.875 -9e-6,0.424133 0.293541,1.061183 0.84375,1.875 l 3.5625,5.34375 4.15625,-5.25 c 0.481406,-0.618955 0.771818,-1.051979 0.875,-1.28125 0.11461,-0.229229 0.187481,-0.446767 0.1875,-0.6875 -1.9e-5,-0.240691 -0.112469,-0.472828 -0.25,-0.65625 -0.171956,-0.24069 -0.361381,-0.40828 -0.625,-0.5 -0.263655,-0.10314 -0.830966,-0.14476 -1.65625,-0.15625 l 0,-0.625 8.28125,0 0,0.625 c -0.653386,0.03441 -1.181122,0.140585 -1.59375,0.3125 -0.618997,0.263659 -1.171709,0.615484 -1.6875,1.0625 -0.515833,0.447058 -1.278845,1.265207 -2.21875,2.46875 l -4.625,5.90625 5.03125,7.46875 c 1.386942,2.063254 2.397654,3.387302 3.0625,3.9375 0.676265,0.538738 1.530851,0.81769 2.5625,0.875 l 0,0.625 -10,0 0,-0.625 c 0.66481,-0.01146 1.147784,-0.06141 1.46875,-0.1875 0.240697,-0.103161 0.44472,-0.262423 0.59375,-0.46875 0.16046,-0.217786 0.249982,-0.438461 0.25,-0.65625 -1.8e-5,-0.263636 -0.05311,-0.54886 -0.15625,-0.8125 -0.08025,-0.19486 -0.418566,-0.686159 -0.96875,-1.5 l -3.9375,-5.96875 -4.875,6.25 c -0.515819,0.664828 -0.834344,1.114502 -0.9375,1.34375 -0.10316,0.217789 -0.156256,0.44679 -0.15625,0.6875 -6e-6,0.366801 0.159256,0.665539 0.46875,0.90625 0.30948,0.240713 0.910092,0.37186 1.78125,0.40625 l 0,0.625 -8.28125,0 0,-0.625 c 0.584586,-0.05731 1.075886,-0.160349 1.5,-0.34375 0.710673,-0.298024 1.389347,-0.714398 2.03125,-1.21875 0.641896,-0.504347 1.393444,-1.26941 2.21875,-2.3125 l 5.5,-6.9375 -4.59375,-6.75 c -1.249419,-1.822518 -2.316354,-3.000816 -3.1875,-3.5625 -0.871152,-0.573103 -1.865215,-0.87184 -3,-0.90625 l 0,-0.625 z m -19.3125,7.34375 17.96875,0 0.25,5.09375 -0.6875,0 c -0.240731,-1.226469 -0.514493,-2.07273 -0.8125,-2.53125 -0.28658,-0.458478 -0.708141,-0.821767 -1.28125,-1.0625 -0.458515,-0.17192 -1.279802,-0.249978 -2.4375,-0.25 l -6.375,0 0,9.21875 5.125,0 c 1.329636,1.3e-5 2.209198,-0.192549 2.65625,-0.59375 0.596035,-0.52726 0.93121,-1.451586 1,-2.78125 l 0.625,0 0,8.125 -0.625,0 c -0.160491,-1.134778 -0.30829,-1.897791 -0.46875,-2.21875 -0.206341,-0.401177 -0.561302,-0.708239 -1.03125,-0.9375 -0.469976,-0.229239 -1.181951,-0.343739 -2.15625,-0.34375 l -5.125,0 0,7.6875 c -7e-6,1.031628 0.0333,1.677002 0.125,1.90625 0.09169,0.217789 0.239493,0.393702 0.46875,0.53125 0.229242,0.12609 0.701842,0.187501 1.34375,0.1875 l 3.9375,0 c 1.318173,10e-7 2.278935,-0.09785 2.875,-0.28125 0.596034,-0.183399 1.137283,-0.55501 1.6875,-1.09375 0.710657,-0.710672 1.473668,-1.754683 2.21875,-3.1875 l 0.6875,0 -2,5.8125 -17.96875,0 0,-0.625 0.8125,0 c 0.550198,0 1.069611,-0.111362 1.5625,-0.375 0.366797,-0.183395 0.592659,-0.476948 0.71875,-0.84375 0.13755,-0.366798 0.218745,-1.11521 0.21875,-2.25 l 0,-15.15625 c -5e-6,-1.478642 -0.139479,-2.374854 -0.4375,-2.71875 -0.412653,-0.458478 -1.099652,-0.687478 -2.0625,-0.6875 l -0.8125,0 0,-0.625 z"></path></svg>
          </span>
          <span>Bibtex</span>
          </a>
      </span> -->
      <!-- Dataset Link.
      <span class="link-block">
        <a href="https://github.com/google/nerfies/releases/tag/0.1"
           class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
              <i class="far fa-images"></i>
          </span>
          <span>Data</span>
          </a> -->
    </div>

  </div>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">Video</h2> -->
        <div class="publication-video">
            <!-- <iframe src="" type="video/mp4"
              frameborder="0" allow="autoplay" allowfullscreen>
            </iframe> -->

            <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/hubAbximDuc?si=WqaTnnUJ-o4R-NM5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> -->
            
            <video poster="" id="opening-video" autoplay controls muted playsinline height="100%">
              <source src="static/videos/main.mp4"
                      type="video/mp4">
              </video>      
        </div>
        <!-- <div class="subtitle">
          
        </div> -->
      </div>
    </div>
    <!--/ Paper video. -->
  
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          We study the problem of teaching humanoid robots manipulation skills by imitating from single video demonstrations. We introduce OKAMI, a method that generates a manipulation plan from a single RGB-D video and derives a policy for execution. At the heart of our approach is object-aware retargeting, which enables the humanoid robot to mimic the human motions in an RGB-D video while adjusting to different object locations during deployment. OKAMI uses open-world vision models to identify task-relevant objects and retarget the body motions and hand poses separately. Our experiments show that OKAMI achieves strong generalizations across varying visual and spatial conditions, outperforming the state-of-the-art baseline on open-world imitation from observation. Furthermore, OKAMI rollout trajectories are leveraged to train closed-loop visuomotor policies, which achieve an average success rate of 79.2% without the need for labor-intensive teleoperation.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<hr>
<br>
<br>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method Overview. -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Method</h2>

        <div class="content has-text-justified">
          OKAMI is a two-staged method that enables a humanoid robot to imitate a manipulation task from a single human video. 
          The first stage helps the humanoid to understand what is happening in the actionless video, and the second stage allows the humanoid to execute the task in various scenarios. 
        </div>

        <div class="content has-text-justified">
          <!-- To follow a human video, the humanoid needs to understand both object-centric information and how human motion behaves. Also, a task can be arbitrarily long and involve multiple subgoals. -->
          In the first stage, OKAMI processes the human video to generate a reference manipulatation plan, a spatiotemporal abstraction of the video that captures which and how objects are moved and how human moves between adjacent subgoals. 
          It first identify task-relevant objects using VLM, then tracks the object motions throughout the video. 
          It use a human reconstruction model to obtain SMPL-H trajectories. 
          Subgoals are identified based on objects keypoints velocities, then all information are combined to form the reference plan.
        </div>

        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <video class="robot-video is-centered" poster="" id="method1" autoplay controls loop muted playsinline height="100%">
              <source src="./static/videos/method1.mp4"
                      type="video/mp4">
              </video>
          </div>
        </div>

        <div class="content has-text-justified">
          In the second stage, the humanoid motion is synthesized through object-aware retargeting, which retargets the human motion to the humanoid while adapting to the object locations during deployment. 
          <!-- The humanoid follows the reference plan step-by-step, and performs motion retargeting for each step.  -->
          It first localizes the task-relevant objects and retrives the subgoal. Then it retargets the SMPL-H trajectory to the humanoid, using inverse kinematics and dex-retargeting. The trajectory is warped based on test-time object's locations, and then sent to the real robot for execution.
        </div>

        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <video class="robot-video is-centered" poster="" id="method1" autoplay controls loop muted playsinline height="100%">
              <source src="./static/videos/method2.mp4"
                      type="video/mp4">
              </video>
          </div>
        </div>
    </div>
  </div>

  <br>
  <br>
  <!-- <div class="container is-max-desktop">
  <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h4 class="subtitle is-3">Method - Action Synthesis of OKAMI Policy</h4>
    <div>
      <img id="teaser" src="./static/imgs/action_synthesis.svg" alt="No image found."/>
      <div class="content has-text-justified">
        At test time, OKAMI first localizes task-relevant objects and retrieves
        the matched OOG from the generated manipulation plan. Then OKAMI uses
        the retrieved OOGs to predict the object motions by first computing
        global registration of object point clouds and then warping the
        observed keypoint trajectories from video into the workspace. The
        predicted trajectories are then used to optimize the SE(3) action
        sequence of the robot end effector, which is subsequently used to
        command the robot.
    </div>
    </div>
  </div>
</div>
</div>
</div>
</section> -->

<!-- <br><hr><br>
<section class="section">
  <div class="container is-max-desktop">
    <p class="carousel-title" id="toggleButton-human-video-demo">Human Video Demos</p>
    <div class="toggleContent" id="toggleContent-human-video-demo">
      <div class="example-slick">
        {% for video in site.data.video_human_demo %}
              <div class="{{ video.class }} is-centered">
                  <video class="human-video is-centered" poster="" id="{{ video.id }}" muted loop playsinline height="100%">
                  <source src="{{ video.src }}"
                          type="{{ video.type }}">
                  </video>   
                  <div class="caption" style="font-size:20px!important"> Task: <br> {{ video.caption }} </div>         
                  <br>
              </div>
        {% endfor %}
      </div>
    </div>
    <p class="content has-text-justified"> Here we show all the videos of human demonstrations. All the videos are taken using the realsense camera mounted on the humanoid's head. </p>
  </div>
</section> -->

<br><hr><br>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Content to be toggled -->
    <h2 class="title is-3 sectiont-title">Object-Aware Retarget Results</h2>
    <p class="content has-text-justified"> We test object-aware retarget on the real robot on six representative tasks, which covers a wide range of manipulation skills including picking, placing, pouring, pushing, manipulating articulated objects, and bimanual cooperation.
      Our method enables the humanoid to perform the task in scenerios with different visual backgrounds, different object instances, and different object layouts. Here we provide the rollout videos of the six tasks. </p>
    
    <h2 class="subtitle is-3 is-centered">Task: Bagging</h2>
    <div class="columns">
      <div class="column is-4">
        <div>
          <video class="robot-video is-centered" poster="" id="bagging" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/human_demo/bagging_human_demo.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:20px!important"> Human demonstration video </div>
        </div>
      </div>
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="bagging" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/grid_videos/bagging_grid.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:20px!important"> Robot rollout video </div>
        </div>
      </div>
    </div>
    
    <h2 class="subtitle is-3 is-centered">Task: Sprinkle-salt</h2>
    <div class="columns">
      <div class="column is-4">
        <div>
          <video class="robot-video is-centered" poster="" id="salt" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/human_demo/salt_human_demo.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:20px!important"> Human demonstration video </div>
        </div>
      </div>
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="salt" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/grid_videos/salt_grid.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:20px!important"> Robot rollout video </div>
        </div>
      </div>
    </div>
    
    <h2 class="subtitle is-3 is-centered">Task: Plush-toy-in-basket</h2>
    <div class="columns">
      <div class="column is-4">
        <div>
          <video class="robot-video is-centered" poster="" id="plush_toy" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/human_demo/plush_toy_human_demo.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:20px!important"> Human demonstration video </div>
        </div>
      </div>
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="plush_toy" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/grid_videos/plush_toy_grid.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:20px!important"> Robot rollout video </div>
        </div>
      </div>
    </div>
    
    <h2 class="subtitle is-3 is-centered">Task: Place-snacks-on-plate</h2>
    <div class="columns">
      <div class="column is-4">
        <div>
          <video class="robot-video is-centered" poster="" id="snack" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/human_demo/snack_human_demo.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:20px!important"> Human demonstration video </div>
        </div>
      </div>
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="snack" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/grid_videos/snack_grid.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:20px!important"> Robot rollout video </div>
        </div>
      </div>
    </div>
    
    <h2 class="subtitle is-3 is-centered">Task: Close-the-drawer</h2>
    <div class="columns">
      <div class="column is-4">
        <div>
          <video class="robot-video is-centered" poster="" id="drawer" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/human_demo/close_drawer_human_demo.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:20px!important"> Human demonstration video </div>
        </div>
      </div>
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="drawer" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/grid_videos/drawer_grid.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:20px!important"> Robot rollout video </div>
        </div>
      </div>
    </div>
    
    <h2 class="subtitle is-3 is-centered">Task: Close-the-laptop</h2>
    <div class="columns">
      <div class="column is-4">
        <div>
          <video class="robot-video is-centered" poster="" id="laptop" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/human_demo/close_laptop_human_demo.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:20px!important"> Human demonstration video </div>
        </div>
      </div>
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="laptop" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/grid_videos/laptop_grid.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:20px!important"> Robot rollout video </div>
        </div>
      </div>
    </div>

  </div>
</section>

<br><hr><br>

<section class="section">
  <div class="container is-max-desktop">
    <!-- <p class="carousel-title" id="toggleButton-human-video-demo">Visuomotor Policy Rollout</p> -->
    <h2 class="title is-3 is-centered">Closed-Loop Visuomotor Policies</h2>
    <p class="content has-text-justified"> By randomly initializing the object layouts and running the object-aware retargeting pipeline each time, we can efficiently generate a large volume of successful rollout data using OKAMI without the need for human-teleoperation. The rollout data can then be used to train closed-loop visuomotor policies through behavioral cloning. 
     We test on two tasks, bagging and sprinkle-salt. The success rates of the visuomotor policies achieve 83.3% and 75% respectively. Here we provide the rollouts of visuomotor policies. </p>

    <div class="columns is-max-desktop">
      <div class="column">
        <!-- <h2 class="subtitle is-4 is-centered">Task: Bagging</h2> -->
        <div>
          <video class="robot-video is-centered" poster="" id="bagging" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/visuomotor/bc_bagging.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:20px!important"> Task: Bagging </div>
        </div>
      </div>
      
      <div class="column">
        <!-- <h2 class="subtitle is-4 is-centered">Task: Sprinkle-salt</h2> -->
        <div>
          <video class="robot-video is-centered" poster="" id="pouring" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/visuomotor/bc_pouring.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:20px!important"> Task: Sprinkle-salt </div>
        </div>
      </div>

    </div>
  </div>
</section>

<br><hr><br>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 is-centered">Failure Examples</h2>
    <p class="content has-text-justified"> OKAMI's policies may fail to grasp objects due to inaccuracies in the robot controllers, the human reconstruction model or the vision models, or fail to complete tasks because of unwanted collisions, undesired upper body rotations, or inaccuracy in solving inverse kinematics. Here we provide typical failure examples. </p>

    <div class="columns is-max-desktop is-multiline">
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="fail1" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/failure_videos/fail_to_grasp_bagging.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:15px!important"> Failed to grasp the snack because the robot hand didn't move to a proper position for grasping. </div>
        </div>
      </div>
      
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="fail2" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/failure_videos/fail_to_grasp.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:15px!important"> Failed to grasp the bottle because the robot hand didn't move to a proper position for grasping. </div>
        </div>
      </div>
    </div>

    <div class="columns is-max-desktop">
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="fail3" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/failure_videos/fail_to_complete1.mp4"
                    type="video/mp4">
            </video>   
          <div class="caption" style="font-size:15px!important"> Failed to complete the task because of inaccurate inverse kinematics results. </div>
        </div>
      </div>
      
      <div class="column">
        <div>
          <video class="robot-video is-centered" poster="" id="fail4" controls muted autoplay loop playsinline height="100%">
            <source src="./static/videos/failure_videos/fail_to_complete2.mp4"
                    type="video/mp4">
            </video>   
            <div class="caption" style="font-size:15px!important"> Failed to complete the task due to unwanted collisions and unwanted body rotation. </div>
        </div>
      </div>
    </div>
    
  </div>
</section>

<br><hr><br>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 is-centered">Team</h2>

    <div class="columns is-max-desktop has-text-centered is-multiline">
      <div class="column is-2 is-offset-1">
        <div class="card-image has-text-centered">
          <figure class="image is-128x128 is-inline-block">
            <img class="is-rounded" src="./static/imgs/authors/jinhan.jpg">
          </figure>
        </div>

        <div class="content has-text-centered">
          <a href="">
            Jinhan Li
          </a>
        </div>
      </div>

      <div class="column is-2">

        <div class="card-image has-text-centered">
          <figure class="image is-128x128 is-inline-block">
            <img class="is-rounded" src="./static/imgs/authors/yifeng.jpg">
          </figure>
        </div>

        <div class="content has-text-centered">
          <a href="https://zhuyifengzju.github.io/">
            Yifeng Zhu*
          </a>
        </div>
      </div>

      <div class="column is-2">

        <div class="card-image has-text-centered">
          <figure class="image is-128x128 is-inline-block">
            <img class="is-rounded" src="./static/imgs/authors/yuqi_xie.png">
          </figure>
        </div>

        <div class="content has-text-centered">
          <a href="https://xieleo5.github.io/">
            Yuqi Xie*
          </a>
        </div>

      </div>

      <div class="column is-2">

        <div class="card-image has-text-centered">
          <figure class="image is-128x128 is-inline-block">
            <img class="is-rounded" src="./static/imgs/authors/zhenyu_jiang.jpg">
          </figure>
        </div>

        <div class="content has-text-centered">
          <a href="https://zhenyujiang.me/">
            Zhenyu Jiang*
          </a>
        </div>

      </div>

      <div class="column is-2">

        <div class="card-image has-text-centered">
          <figure class="image is-128x128 is-inline-block">
            <img class="is-rounded" src="./static/imgs/authors/mingyo_seo.png">
          </figure>
        </div>

        <div class="content has-text-centered">
          <a href="https://mingyoseo.com/">
            Mingyo Seo
          </a>
        </div>

      </div>
    </div>

    <div class="columns is-max-desktop has-text-centered is-multiline">
      <div class="column is-2 is-offset-4">

        <div class="card-image has-text-centered">
          <figure class="image is-128x128 is-inline-block">
            <img class="is-rounded" src="./static/imgs/authors/georgios_pavlakos.jpg">
          </figure>
        </div>

        <div class="content has-text-centered">
          <a href="https://geopavlakos.github.io/">
            <!-- <div class="mb-2"></div> -->
            Georgios Pavlakos
          </a>
        </div>

      </div>

      <div class="column is-2">

        <div class="card-image has-text-centered">
          <figure class="image is-128x128 is-inline-block">
            <img class="is-rounded" src="./static/imgs/authors/yuke_zhu.jpg">
          </figure>
        </div>

        <div class="content has-text-centered">
          <a href="https://yukezhu.me/">
            Yuke Zhu
          </a>
        </div>
      </div>

    </div>
    <br>

    <h2 class="title is-3 is-centered">Citation</h2>
    <pre><code class="bibref"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">okami2024</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Jinhan Li and Yifeng Zhu and Yuqi Xie and Zhenyu Jiang and Mingyo Seo and Georgios Pavlakos and Yuke Zhu}</span><span class="p">,</span>
    <span class="na">booktitle</span><span class="p">=</span><span class="s">{8th Annual Conference on Robot Learning (CoRL)}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span></code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">

    <div class="container is-max-desktop">
      <!-- Method Overview. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Acknowledgement</h2>
          <div class="content has-text-justified">
            We would like to thank William Yue for providing the initial implementation of the behavior cloning policies, Peter Stone for his valuable support with task design and demo shooting, Yuzhe Qin for sharing the dex-retargeting codebase, and Zhenjia Xu for his help in developing the the humanoid's infrastructure.
          </div>
        </div>
      </div>
  </div>
</footer>
</body>
</html>
